.. _run_examples:

Run examples
==================================
This sections gives examples on how to use the three modes of TandemMod.

Train m6A model using IVET m6A dataset
********************
IVET datasets have been uploaded to GEO database under the accession number `GSE227087 <https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE227087>`_. To train a m6A detection model, the followinng two fast5 files (m6A-modified and unmodified) are required.
::
    IVET_DRS_m6A.tar.gz 
    IVET_DRS_unmodified.tar.gz 
    

In this demo, subsets of the two datasets were taken for demonstration purposes due to the large size of the original datasets. The demo datasets were located undelr ``./demo/IVET/`` directory.
::
    demo
    └── IVET
        ├── IVET_m6A
        │   └── IVET_m6A.fast5
        └── IVET_unmod
            └── IVET_unmod.fast5


**1. Guppy basecalling**
Basecalling converts the raw signal generated by Oxform Nanopore sequencing to DNA/RNA sequence. Guppy is used for basecalling in this step. In some nanopore datasets, the sequence information is already contained within the FAST5 files. In such cases, the basecalling step can be skipped as the sequence data is readily available.
::
    #m6A 
    guppy_basecaller -i demo/IVET/IVET_m6A -s demo/IVET/IVET_m6A_guppy --num_callers 40 --recursive --fast5_out --config rna_r9.4.1_70bps_hac.cfg
    
    #unmodified
    guppy_basecaller -i demo/IVET/IVET_unmod -s demo/IVET/IVET_unmod_guppy --num_callers 40 --recursive --fast5_out --config rna_r9.4.1_70bps_hac.cfg

**2. Multi-reads FAST5 files to single-read FAST5 files**

Convert multi-reads FAST5 files to single-read FAST5 files. If the data generated by the sequencing device is already in the single-read format, this step can be skipped.
::
    #m6A 
    multi_to_single_fast5 -i demo/IVET/IVET_m6A_guppy -s demo/IVET/IVET_m6A_guppy_single --recursive
    
    #unmodified
    multi_to_single_fast5 -i demo/IVET/IVET_unmod_guppy -s demo/IVET/IVET_unmod_guppy_single --recursive

**3. Tombo resquiggling**
In this step, the sequence obtained by basecalling is aligned or mapped to a reference genome or a known sequence. Then the corrected sequence is then associated with the corresponding current signals. The resquiggling process is typically performed in-plac. No separate files are generated in this step.
::
    #m6A
    tombo resquiggle --overwrite --basecall-group Basecall_1D_001 demo/IVET/IVET_m6A_guppy_single  demo/IVET_reference.fa --processes 40 --fit-global-scale --include-event-stdev
    
    #unmodified
    tombo resquiggle --overwrite --basecall-group Basecall_1D_001 demo/IVET/IVET_unmod_guppy_single  demo/IVET_reference.fa --processes 40 --fit-global-scale --include-event-stdev

**4. Map reads to reference**
minimap2 is used to map basecalled sequences to reference transcripts. The output sam file serves as the input for the subsequent feature extraction step. 
::
    #m6A
    cat demo/IVET/IVET_m6A_guppy/pass/*.fastq >demo/IVET/IVET_m6A.fastq
    minimap2 -ax map-ont demo/IVET_reference.fa demo/IVET/IVET_m6A.fastq >demo/IVET/IVET_m6A.sam

    #unmodified
    cat demo/IVET/IVET_unmod_guppy/pass/*.fastq >demo/IVET/IVET_unmod.fastq
    minimap2 -ax map-ont demo/IVET_reference.fa demo/IVET/IVET_unmod.fastq >demo/IVET/IVET_unmod.sam

**5. Feature extraction**
Extract signals and features from resquiggled fast5 files using the following python scripts.
::
    #m6A
    python scripts/extract_signal_from_fast5.py -p 40 --fast5 demo/IVET/IVET_m6A_guppy_single --reference demo/IVET_reference.fa --sam demo/IVET/IVET_m6A.sam --output demo/IVET/m6A.signal.tsv --clip=10
    python scripts/extract_feature_from_signal.py  --signal_file demo/IVET/m6A.signal.tsv --clip 10 --output demo/IVET/m6A.feature.tsv --motif DRACH
    
    #unmodified
    python scripts/extract_signal_from_fast5.py -p 40 --fast5 demo/IVET/IVET_unmod_guppy_single --reference demo/IVET_reference.fa --sam demo/IVET/IVET_unmod.sam --output demo/IVET/unmod.signal.tsv --clip=10
    python scripts/extract_feature_from_signal.py  --signal_file demo/IVET/unmod.signal.tsv --clip 10 --output demo/IVET/unmod.feature.tsv --motif DRACH

In the feature extraction step, the motif pattern should be provided using the argument ``--motif``. The base symbols of the motif follow the IUB code standard. Here is the full definition of IUB base symbols:

+-------------+-------------+
| IUB Base    | Expansion   |
+=============+=============+
| A           | A           |
+-------------+-------------+
| C           | C           |
+-------------+-------------+
| G           | G           |
+-------------+-------------+
| T           | T           |
+-------------+-------------+
| M           | AC          |
+-------------+-------------+
| V           | ACG         |
+-------------+-------------+
| R           | AG          |
+-------------+-------------+
| H           | ACT         |
+-------------+-------------+
| W           | AT          |
+-------------+-------------+
| D           | AGT         |
+-------------+-------------+
| S           | CG          |
+-------------+-------------+
| B           | CGT         |
+-------------+-------------+
| Y           | CT          |
+-------------+-------------+
| N           | ACGT        |
+-------------+-------------+
| K           | GT          |
+-------------+-------------+



**6. Train-test split**
The train-test split is performed randomly, ensuring that the data points in each set are representative of the overall dataset. The default split ratios are 80% for training and 20% for testing. The train-test split ratio can be customized by using the argument "--train_ratio" to accommodate the specific requirements of the problem and the size of the dataset.

The training set is used to train the model, allowing it to learn patterns and relationships present in the data. The testing set, on the other hand, is used to assess the model's performance on new, unseen data. It serves as an independent evaluation set to measure how well the trained model generalizes to data it has not encountered before. By evaluating the model on the testing set, we can estimate its performance, detect overfitting (when the model performs well on the training set but poorly on the testing set) and assess its ability to make accurate predictions on new data.

::
    #m6A
    python scripts/train_test_split.py --input_file demo/IVET/m6A.feature.tsv --train_file demo/IVET/m6A.train.feature.tsv --test_file demo/IVET/m6A.test.feature.tsv --train_ratio 0.8
    
    #unmodified
    python scripts/train_test_split.py --input_file demo/IVET/unmod.feature.tsv --train_file demo/IVET/unmod.train.feature.tsv --test_file demo/IVET/unmod.test.feature.tsv --train_ratio 0.8


**7. Train m6A model**
To train the TandemMod model using your own dataset from scratch, you can set the -run_mode argument to “train”. TandemMod accepts both modified and unmodified feature files as input. Additionally, test feature files are necessary to evaluate the model's performance. You can specify the model save path by using the argument ``--new_model``. The model's training epochs can be defined using the argument ``--epochs``, and the model states will be saved at the end of each epoch. TandemMod will preferentially use the ``GPU`` for training if CUDA is available on your device; otherwise, it will utilize the ``CPU`` mode. The training process duration can vary, depending on the size of your dataset and the computational capacity, and may last for several hours. 
::
    python scripts/TandemMod.py --run_mode train \
      --new_model demo/model/m6A.demo.IVET.pkl \
      --train_data_mod demo/IVET/m6A.train.feature.tsv \
      --train_data_unmod demo/IVET/unmod.train.feature.tsv \
      --test_data_mod demo/IVET/m6A.test.feature.tsv \
      --test_data_unmod demo/IVET/unmod.test.feature.tsv \
      --epoch 100

During training process, the following information can be used to monitor and evaluate the performance of the model:
::
    device= cpu
    train process.
    data loaded.
    Start training...
    Epoch 0-0 Train acc: 0.494000,Test Acc: 0.581081,time0:00:08.936393
    Epoch 1-0 Train acc: 0.514000,Test Acc: 0.817568,time0:00:06.084542
    Epoch 2-0 Train acc: 0.796000,Test Acc: 0.668919,time0:00:06.000019
    Epoch 3-0 Train acc: 0.672000,Test Acc: 0.770270,time0:00:07.456637
    Epoch 4-0 Train acc: 0.786000,Test Acc: 0.763514,time0:00:06.132852
    Epoch 5-0 Train acc: 0.824000,Test Acc: 0.834459,time0:00:06.584059
    Epoch 6-0 Train acc: 0.810000,Test Acc: 0.814189,time0:00:06.600892
    Epoch 7-0 Train acc: 0.780000,Test Acc: 0.790541,time0:00:07.301838

After the data processing and model training, the following files should be generated by TandemMod. The trained model ``m6A.demo.IVET.pkl`` will be saved in the ``./demo/model/`` folder. You can utilize this model for future predictions.
::
    demo
    ├── IVET
    │   ├── IVET_m6A
    │   ├── IVET_m6A.fastq
    │   ├── IVET_m6A_guppy
    │   ├── IVET_m6A_guppy_single
    │   ├── IVET_m6A.sam
    │   ├── IVET_unmod
    │   ├── IVET_unmod.fastq
    │   ├── IVET_unmod_guppy
    │   ├── IVET_unmod_guppy_single
    │   ├── IVET_unmod.sam
    │   ├── m6A.feature.tsv
    │   ├── m6A.signal.tsv
    │   ├── m6A.test.feature.tsv
    │   ├── m6A.train.feature.tsv
    │   ├── unmod.feature.tsv
    │   ├── unmod.signal.tsv
    │   ├── unmod.test.feature.tsv
    │   └── unmod.train.feature.tsv
    ├── IVET_reference.fa
    └── model
           └── m6A.demo.IVET.pkl


Train m6A model using curlcake m6A dataset
********************




Transfer m6A model to m7G using ELIGOS dataset
********************




Predict m6A sites in human cell lines
********************